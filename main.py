# Thesaurus

import pandas as pd
from datetime import datetime, timedelta, time
import os
import requests
from requests.exceptions import RequestException
import matplotlib.pyplot as plt
from dotenv import load_dotenv
import logging
import matplotlib.dates as mdates
import re

import sys


import holidays
from datetime import date

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
log_dir = os.path.join(os.getcwd(), "log")
os.makedirs(log_dir, exist_ok=True)

# –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ª–æ–≥-—Ñ–∞–π–ª—É
log_file = os.path.join(log_dir, "ruonia_log.txt")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    encoding="utf-8"
)

logger = logging.getLogger(__name__)


def is_russian_workday(check_date=None):
    if check_date is None:
        check_date = date.today()

    ru_holidays = holidays.Russia()




    return check_date not in ru_holidays # –≤—ã—Ö–æ–¥–Ω—ã–µ —Å–± –≤—Å –∏    
    # return check_date.weekday() < 5 and check_date not in ru_holidays # –≤—ã—Ö–æ–¥–Ω—ã–µ —Å–± –≤—Å –∏


# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞ –∫–∞–∫–æ–π –ø—Ä–æ–º–µ–∂—É—Ç–µ–∫ –Ω—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —Å–µ–≥–æ–¥–Ω—è, 
def check_if_need_new_rec(FILENAME="ruonia_data.xlsx"):
    try:
        today = datetime.today().date()
        end_date = today.strftime("%d.%m.%Y")
        start_date = "11.01.2010"
        from_dt = datetime.strptime(start_date, "%d.%m.%Y").strftime("%m/%d/%Y")
        to_dt = today.strftime("%m/%d/%Y")

        if os.path.exists(FILENAME):
            try:
                local_df = pd.read_excel(FILENAME)
                local_df["–î–∞—Ç–∞"] = pd.to_datetime(local_df["–î–∞—Ç–∞"], dayfirst=True)
                last_date = local_df["–î–∞—Ç–∞"].max().date()
                from_date = local_df["–î–∞—Ç–∞"].min().date()

                logger.info(f"–§–∞–π–ª –Ω–∞–π–¥–µ–Ω. –° {from_date} –ø–æ {last_date}")

                if not is_russian_workday():
                    # logger.info("–°–µ–≥–æ–¥–Ω—è –≤—ã—Ö–æ–¥–Ω–æ–π –∏–ª–∏ –ø—Ä–∞–∑–¥–Ω–∏–∫ ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
                    logger.info("–ü—Ä–∞–∑–¥–Ω–∏–∫ ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
                    return 0

                if last_date.strftime('%d.%m.%Y') == today.strftime('%d.%m.%Y') or (
                    last_date.strftime('%d.%m.%Y') == (today - timedelta(days=1)).strftime('%d.%m.%Y') and
                    datetime.now().time() < time(14, 0)
                ):
                    logger.info("–î–∞–Ω–Ω—ã–µ —É–∂–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
                    return 0
                else:
                    logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ. –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
                logger.info("–í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∑–∞–Ω–æ–≤–æ.")
        else:
            logger.info(f"–§–∞–π–ª {FILENAME} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å {start_date} –ø–æ {end_date}.")

        url = f"https://cbr.ru/Queries/UniDbQuery/DownloadExcel/125022?Posted=True&From={start_date}&To={end_date}&I1=true&M1=true&M3=true&M6=true&FromDate={from_dt}&ToDate={to_dt}"
        logger.info(f"–ó–∞–ø—Ä–æ—Å –ø–æ —Å—Å—ã–ª–∫–µ: {url}")

        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return -1

        with open(FILENAME, "wb") as f:
            f.write(response.content)
            logger.info(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {FILENAME}")

        return 1

    except RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å —Å–∞–π—Ç–∞ –¶–ë: {e}")
        return -1
    except Exception as e:
        logger.exception(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return -2


# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤, –ø–æ—Ö–æ–∂–µ –Ω–∞ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
def analitics(FILENAME="ruonia_data.xlsx"):
    today_str = datetime.today().strftime("%Y-%m-%d")
    base_filename = f"ruonia_trend_{today_str}"
    ext = ".png"

    output_dir = os.path.join(os.getcwd(), "src")
    os.makedirs(output_dir, exist_ok=True)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞
    version = 1
    output_path = os.path.join(output_dir, base_filename + ext)
    while os.path.exists(output_path):
        version += 1
        output_path = os.path.join(output_dir, f"{base_filename}_v{version}{ext}")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = pd.read_excel(FILENAME)
        df = df.rename(columns={
            "–ò–Ω–¥–µ–∫—Å": "RUONIA",
            "1 –º–µ—Å—è—Ü": "1 –º–µ—Å",
            "3 –º–µ—Å—è—Ü–∞": "3 –º–µ—Å",
            "6 –º–µ—Å—è—Ü–µ–≤": "6 –º–µ—Å"
        })
        df["–î–∞—Ç–∞"] = pd.to_datetime(df["–î–∞—Ç–∞"], dayfirst=True)
        df = df.dropna(subset=["RUONIA", "1 –º–µ—Å", "3 –º–µ—Å", "6 –º–µ—Å"])
        df = df.sort_values("–î–∞—Ç–∞")

        # --- üìà –ì—Ä–∞—Ñ–∏–∫ —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏ ---
        plt.figure(figsize=(14, 7))
        plt.plot(df["–î–∞—Ç–∞"], df["RUONIA"], label="RUONIA (overnight)", linewidth=2)
        plt.plot(df["–î–∞—Ç–∞"], df["1 –º–µ—Å"], label="RUONIA 1 –º–µ—Å", linestyle="--")
        plt.plot(df["–î–∞—Ç–∞"], df["3 –º–µ—Å"], label="RUONIA 3 –º–µ—Å", linestyle="-.")
        plt.plot(df["–î–∞—Ç–∞"], df["6 –º–µ—Å"], label="RUONIA 6 –º–µ—Å", linestyle=":")

        plt.title(f"–î–∏–Ω–∞–º–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ RUONIA –∏ —Å—Ä–æ—á–Ω—ã—Ö —Å—Ç–∞–≤–æ–∫ –¥–æ {today_str}", fontsize=14)
        plt.xlabel("–î–∞—Ç–∞")
        plt.ylabel("–°—Ç–∞–≤–∫–∞ (%)")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(output_path)
        plt.close()

        logger.info(f"üìà –ì—Ä–∞—Ñ–∏–∫ (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ) —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

        # --- üìâ –ì—Ä–∞—Ñ–∏–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π ---
        short_df = df[df["–î–∞—Ç–∞"] >= (datetime.today() - timedelta(days=90))]

        plt.figure(figsize=(14, 7))
        plt.plot(short_df["–î–∞—Ç–∞"], short_df["1 –º–µ—Å"], label="RUONIA 1 –º–µ—Å", linestyle="--")
        plt.plot(short_df["–î–∞—Ç–∞"], short_df["3 –º–µ—Å"], label="RUONIA 3 –º–µ—Å", linestyle="-.")
        plt.plot(short_df["–î–∞—Ç–∞"], short_df["6 –º–µ—Å"], label="RUONIA 6 –º–µ—Å", linestyle=":")

        plt.title(f"RUONIA (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π) –¥–æ {today_str}", fontsize=14)
        plt.xlabel("–î–∞—Ç–∞")
        plt.ylabel("–°—Ç–∞–≤–∫–∞ (%)")
        plt.legend()
        plt.grid(True)

        ax = plt.gca()
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
        plt.xticks(rotation=90)

        plt.tight_layout()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ç–æ—Ä–æ–π —Ñ–∞–π–ª —Å _last90
        short_filename = f"{base_filename}_last90"
        short_output_path = os.path.join(output_dir, short_filename + ext)
        version = 1
        while os.path.exists(short_output_path):
            version += 1
            short_output_path = os.path.join(output_dir, f"{short_filename}_v{version}{ext}")

        plt.savefig(short_output_path)
        plt.close()

        logger.info(f"üìâ –ì—Ä–∞—Ñ–∏–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π) —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {short_output_path}")
        return output_path, short_output_path

    except Exception as e:
        logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
        return None
    
#–ø—Ä–æ–≤–µ—Ç—Å–∏ –∞–Ω–∞–ª–∏–∑ –†–£–û–ù–ò–ò 
def make_analyze_ruonia(filepath="ruonia_data.xlsx"):
    try:
        df = pd.read_excel(filepath)
        df = df.rename(columns={
            "–ò–Ω–¥–µ–∫—Å": "RUONIA",
            "1 –º–µ—Å—è—Ü": "1 –º–µ—Å",
            "3 –º–µ—Å—è—Ü–∞": "3 –º–µ—Å",
            "6 –º–µ—Å—è—Ü–µ–≤": "6 –º–µ—Å"
        })
        df["–î–∞—Ç–∞"] = pd.to_datetime(df["–î–∞—Ç–∞"], dayfirst=True)
        df = df.sort_values("–î–∞—Ç–∞")

        last_30 = df.tail(30)
        last_15 = last_30.tail(15)
        last_10 = last_30.tail(10)

        latest_date = last_10["–î–∞—Ç–∞"].iloc[-1].strftime("%d.%m.%Y")
        previous_date = last_10["–î–∞—Ç–∞"].iloc[-2].strftime("%d.%m.%Y")

        indicators = ["RUONIA", "1 –º–µ—Å", "3 –º–µ—Å", "6 –º–µ—Å"]
        full_text = f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {latest_date}\n"

        for col in indicators:
            latest = last_10[col].iloc[-1]
            previous = last_10[col].iloc[-2]

            delta_1 = latest - previous
            delta_10 = last_10[col].iloc[-1] - last_10[col].iloc[0]
            delta_15 = last_15[col].iloc[-1] - last_15[col].iloc[0]
            delta_30 = last_30[col].iloc[-1] - last_30[col].iloc[0]

            mean_10 = last_10[col].mean()
            mean_15 = last_15[col].mean()
            mean_30 = last_30[col].mean()

            if delta_10 > 0 and delta_15 > 0 and delta_30 > 0:
                trend = "üìà –ø–ª–∞–≤–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥"
            elif delta_10 < 0 and delta_15 < 0 and delta_30 < 0:
                trend = "üìâ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ"
            else:
                trend = "üìä –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ"

            full_text += (
                f"\nüìå **{col}**\n"
                f"‚Ä¢ –°–µ–≥–æ–¥–Ω—è: {latest:.4f}\n"
                f"‚Ä¢ –í—á–µ—Ä–∞ ({previous_date}): {previous:.4f}\n"
                f"‚Ä¢ Œî –∑–∞ –¥–µ–Ω—å: {delta_1:+.4f}\n"
                f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–∞ 10 –¥–Ω–µ–π: {mean_10:.4f}\n"
                f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–∞ 15 –¥–Ω–µ–π: {mean_15:.4f}\n"
                f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–∞ 30 –¥–Ω–µ–π: {mean_30:.4f}\n"
                f"‚Ä¢ –†–æ—Å—Ç –∑–∞ 10 –¥–Ω–µ–π: {delta_10:+.4f}\n"
                f"‚Ä¢ –†–æ—Å—Ç –∑–∞ 15 –¥–Ω–µ–π: {delta_15:+.4f}\n"
                f"‚Ä¢ –†–æ—Å—Ç –∑–∞ 30 –¥–Ω–µ–π: {delta_30:+.4f}\n"
                f"‚Ä¢ –¢—Ä–µ–Ω–¥: {trend}\n"
            )

        logger.info("üßæ –ê–Ω–∞–ª–∏–∑ RUONIA —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω.")
        logger.debug(f"\n{full_text}")
        return full_text

    except Exception as e:
        logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ RUONIA: {e}")
        return None


def send_info_ruonia(client, recipients):
    folder_path = os.path.join(os.getcwd(), "src")
    base_name = "ruonia_trend_"
    short_base_name = "ruonia_trend_"
    short_suffix = "_last90"
    extension = ".png"

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤
    matching_files = [
        f for f in os.listdir(folder_path)
        if f.startswith(base_name) and f.endswith(extension) and short_suffix not in f
    ] if os.path.exists(folder_path) else []

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ (last90)
    matching_short_files = [
        f for f in os.listdir(folder_path)
        if f.startswith(short_base_name) and short_suffix in f and f.endswith(extension)
    ] if os.path.exists(folder_path) else []

    # if matching_files:
    #     matching_files.sort(reverse=True)
    #     latest_file = os.path.join(folder_path, matching_files[0])
    #     logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥—Ä–∞—Ñ–∏–∫: {latest_file}")
    # else:
    #     logger.warning("üìÇ –ì—Ä–∞—Ñ–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é analitics()...")
    #     latest_file = analitics()

    #–ó–∞–º–µ–Ω–∏–ª –Ω–∞ –≤—Å–µ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    logger.warning("üìÇ –í—Å–µ–≥–¥–∞!!!!. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é analitics()...")
    # latest_file, latest_short_file = analitics()

    # latest_file = analitics()
    result = analitics()
    if not result:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏.")

    latest_file, latest_short_file = result

    if not os.path.exists(latest_file):
        logger.error("‚ùå –§–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")


    # –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ short-—Ñ–∞–π–ª–∞
    latest_short_file = None
    if matching_short_files:
        matching_short_files.sort(reverse=True)
        latest_short_file = os.path.join(folder_path, matching_short_files[0])
        logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –≥—Ä–∞—Ñ–∏–∫ (90 –¥–Ω–µ–π): {latest_short_file}")





    if not latest_file or not os.path.exists(latest_file):
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–∞ RUONIA.")
        return

    analysis = make_analyze_ruonia()

    for chat_id in recipients:
        try:
            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ —á–∞—Ç: {chat_id}")
            client.send_photo(
                chat_id,
                photo=latest_file,
                caption="üìà –ì—Ä–∞—Ñ–∏–∫ RUONIA –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è –¥–æ " + datetime.today().strftime("%Y-%m-%d")
            )

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ (last90), –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω
            if latest_short_file and os.path.exists(latest_short_file):
                client.send_photo(
                    chat_id,
                    photo=latest_short_file,
                    caption="üìâ RUONIA –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π"
                )

            if analysis:
                client.send_message(chat_id, analysis)
                logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ {chat_id}")
            else:
                logger.warning(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {chat_id}")
        except Exception as e:
            logger.exception(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ {chat_id}: {e}")


# https://cbr.ru/Queries/UniDbQuery/DownloadExcel/125022?Posted=True&From=11.01.2010&To=30.04.2025&I1=true&M1=true&M3=true&M6=true&FromDate=01%2F11%2F2010&ToDate=04%2F30%2F2025

###########################################################################################################################AI
# from functions.ai import run_brief

# # ---------- –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç-–º–µ–Ω–µ–¥–∂–µ—Ä–æ–º ----------
# def send_ai(client, recipients):
#     """
#     –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ (Markdown) —á–µ—Ä–µ–∑ functions.ai.run_brief –∏ —Ä–∞—Å—Å—ã–ª–∞–µ—Ç –µ–≥–æ:
#       ‚Ä¢ –°–ù–ê–ß–ê–õ–ê —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (–ø–æ –¥–≤–µ –≥–ª–∞–≤—ã –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏, —É–∫–ª–∞–¥—ã–≤–∞—è—Å—å –≤ –ª–∏–º–∏—Ç Telegram),
#       ‚Ä¢ –∑–∞—Ç–µ–º –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –∞—Ä—Ö–∏–≤–Ω—ã–π .md —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É src/ai/ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ —á–∞—Ç.

#     –£—Å—Ç–æ–π—á–∏–≤–∞ –∫ —Ä–∞–∑–Ω—ã–º —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º run_brief():
#       - –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å (answer),
#       - –∏–ª–∏ (answer, tokens),
#       - –∏–ª–∏ (answer, tokens, *anything_else).  
#     –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç Markdown (–∑–∞–∫—Ä—ã–≤–∞–µ—Ç ```), –¥–µ–ª–∏—Ç –Ω–∞ –≥–ª–∞–≤—ã `## N. ...`.
#     –ü—Ä–∏ –æ—à–∏–±–∫–µ —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –±–µ–∑ parse_mode.
#     """
#     import os
#     import re
#     from datetime import datetime
#     from functions.ai import run_brief

#     TELEGRAM_LIMIT = 4000

#     # --- helpers -----------------------------------------------------------
#     def normalize_code_fences(text: str) -> str:
#         # –ü—Ä–∏–≤–æ–¥–∏–º ```md/markdown –∫ –ø—Ä–æ—Å—Ç–æ–º—É ``` –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ
#         text = re.sub(r"```\s*(markdown|md|Markdown)\s*\n", "```\n", text)
#         if text.count("```") % 2 == 1:
#             text = text.rstrip() + "\n\n```\n"
#         return text

#     def split_into_chapters(md: str):
#         # –ì–ª–∞–≤–∞ = –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–∞: ## 1. ...
#         header_pat = re.compile(r"^##\s+\d+\.[\t ]*.*$", re.M)
#         matches = list(header_pat.finditer(md))
#         if not matches:
#             return [md]
#         parts = []
#         first_start = matches[0].start()
#         prologue = md[:first_start].strip("\n")
#         if prologue:
#             parts.append(prologue)
#         for i, m in enumerate(matches):
#             start = m.start()
#             end = matches[i+1].start() if i+1 < len(matches) else len(md)
#             parts.append(md[start:end].strip("\n"))
#         return parts

#     def split_hard(block: str, limit: int):
#         # –ê–±–∑–∞—Ü—ã -> —Å—Ç—Ä–æ–∫–∏ -> —Å–∏–º–≤–æ–ª—ã, –Ω–æ—Ä–º–∞–ª–∏–∑—É—è ``` –≤ –∫–∞–∂–¥–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ
#         parts, cur = [], ""
#         def flush():
#             nonlocal cur
#             if cur.strip():
#                 parts.append(normalize_code_fences(cur).strip())
#                 cur = ""
#         for p in block.split("\n\n"):
#             chunk = p + "\n\n"
#             if len(chunk) > limit:
#                 for ln in chunk.splitlines(True):
#                     if len(ln) > limit:
#                         for s in range(0, len(ln), limit):
#                             part = ln[s:s+limit]
#                             if cur and len(cur)+len(part) > limit:
#                                 flush()
#                             cur += part
#                     else:
#                         if cur and len(cur)+len(ln) > limit:
#                             flush()
#                         cur += ln
#             else:
#                 if cur and len(cur)+len(chunk) > limit:
#                     flush()
#                 cur += chunk
#         flush()
#         return parts

#     def bundle_messages(chapters, limit: int):
#         # –°–∫–ª–µ–∏–≤–∞–µ–º –ø–æ 2 –≥–ª–∞–≤—ã, —É–≤–∞–∂–∞—è –ª–∏–º–∏—Ç. –î–ª–∏–Ω–Ω—ã–µ –≥–ª–∞–≤—ã —Ä–µ–∂–µ–º.
#         msgs = []
#         i, n = 0, len(chapters)
#         while i < n:
#             a = normalize_code_fences(chapters[i])
#             if i + 1 < n:
#                 b = normalize_code_fences(chapters[i+1])
#                 if len(a) + len(b) <= limit:
#                     msgs.append((a + "\n\n" + b).strip())
#                     i += 2
#                     continue
#             if len(a) > limit:
#                 msgs.extend(split_hard(a, limit))
#             else:
#                 msgs.append(a)
#             i += 1
#         return msgs

#     # --- get model answer --------------------------------------------------
#     try:
#         result = run_brief()
#     except Exception as e:
#         for chat_id in recipients:
#             try:
#                 client.send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI-brief: {e}")
#             except Exception:
#                 pass
#         return

#     # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–¥ (answer, tokens)
#     answer, tokens = None, None
#     if isinstance(result, tuple):
#         if len(result) >= 1:
#             answer = result[0]
#         if len(result) >= 2:
#             tokens = result[1]
#     else:
#         answer = result

#     if not isinstance(answer, str) or not answer.strip():
#         for chat_id in recipients:
#             try:
#                 client.send_message(chat_id, "‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.")
#             except Exception:
#                 pass
#         return

#     # --- prepare text & files ---------------------------------------------
#     answer = normalize_code_fences(answer)

#     # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω .md —Ñ–∞–π–ª –¥–ª—è –∞—Ä—Ö–∏–≤–∞ –∏ –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ fallback
#     ts = datetime.now().strftime("%Y%m%d_%H%M%S")
#     base_dir = os.path.join(os.getcwd(), "src", "ai")
#     os.makedirs(base_dir, exist_ok=True)
#     md_path = os.path.join(base_dir, f"ai_brief_{ts}.md")
#     with open(md_path, "w", encoding="utf-8") as f:
#         f.write(answer)
#         if tokens:
#             f.write("\n\n" + str(tokens))

#     # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (–æ–¥–Ω–∏–º, –µ—Å–ª–∏ —É–º–µ—â–∞–µ—Ç—Å—è)
#     if len(answer) <= TELEGRAM_LIMIT:
#         messages = [answer]
#     else:
#         chapters = split_into_chapters(answer) or [answer]
#         messages = bundle_messages(chapters, TELEGRAM_LIMIT)

#     # --- send: messages first, then file ----------------------------------
#     for chat_id in recipients:
#         # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Markdown
#         sent_msgs = True
#         try:
#             for i, msg in enumerate(messages, 1):
#                 prefix = f"–ß–∞—Å—Ç—å {i}/{len(messages)}\n\n" if len(messages) > 1 else ""
#                 client.send_message(chat_id, prefix + msg, parse_mode="Markdown")
#         except Exception:
#             sent_msgs = False

#         # 2) –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –±–µ–∑ parse_mode
#         if not sent_msgs:
#             try:
#                 for i, msg in enumerate(messages, 1):
#                     prefix = f"–ß–∞—Å—Ç—å {i}/{len(messages)}\n\n" if len(messages) > 1 else ""
#                     client.send_message(chat_id, prefix + msg)
#                 sent_msgs = True
#             except Exception:
#                 sent_msgs = False

#         # 3) –ö–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–æ —Ç–æ–∫–µ–Ω—ã
#         if tokens and sent_msgs:
#             try:
#                 client.send_message(chat_id, str(tokens))
#             except Exception:
#                 pass

#         # 4) –ò –æ–¥–∏–Ω –∞—Ä—Ö–∏–≤–Ω—ã–π .md —Ñ–∞–π–ª
#         try:
#             client.send_document(chat_id, md_path, caption="üìÑ AI-brief (.md)")
#         except Exception:
#             pass



###########################################################################################################################AI


#################################### –í–µ—Ä–Ω—É—Ç—å ######
# check_if_need_new_rec()

# analitics()  # –õ–∏–±–æ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å 
#################################### –í–µ—Ä–Ω—É—Ç—å ######


###### –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ####
# import subprocess
# import os
# import sys

# def check_git_update(commit_file="log/current_commit.txt"):
#     try:
#         # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ log —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
#         os.makedirs(os.path.dirname(commit_file), exist_ok=True)

#         # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–º–º–∏—Ç —Å origin
#         subprocess.run(["git", "fetch"], check=True)
#         new_commit = subprocess.check_output(
#             ["git", "rev-parse", "origin/main"], text=True
#         ).strip()

#         # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–º–º–∏—Ç
#         if not os.path.exists(commit_file):
#             with open(commit_file, "w") as f:
#                 f.write(new_commit)
#             logger.info(f"üìÑ –§–∞–π–ª {commit_file} —Å–æ–∑–¥–∞–Ω. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–æ–º–º–∏—Ç: {new_commit}")
#             return None  # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è

#         # –°—á–∏—Ç—ã–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –∫–æ–º–º–∏—Ç
#         with open(commit_file, "r") as f:
#             last_commit = f.read().strip()

#         if new_commit != last_commit:
#             logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π –∫–æ–º–º–∏—Ç: {new_commit}")
#             return new_commit
#         else:
#             logger.info("‚úÖ –í–µ—Ä—Å–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–∞. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
#             return None

#     except Exception as e:
#         logger.exception("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Git:")
#         return None


# def update_and_restart(new_commit, commit_file="log/current_commit.txt"):
#     try:
#         subprocess.run(["git", "pull"], check=True)

#         with open(commit_file, "w") as f:
#             f.write(new_commit)

#         logger.info("‚ôªÔ∏è –ü—Ä–æ–µ–∫—Ç –æ–±–Ω–æ–≤–ª—ë–Ω. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º...")
#         os.execv(sys.executable, ['python'] + sys.argv)

#     except Exception as e:
#         logger.exception("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ:")



# commit_file = "log/current_commit.txt"
# new_commit = check_git_update(commit_file)
# if new_commit:
#     update_and_restart(new_commit, commit_file)



################################################################################–í–ï–†–ù–£–¢–¨
from functions.auto_update import check_and_restart_if_updated
check_and_restart_if_updated()
#################################################################################–í–ï–†–ù–£–¢–¨
# ######

load_dotenv()  

api_hash = os.getenv('api_hash')
for_whom = os.getenv('for_whom')
api_id = os.getenv('api_id')
bot_token = os.getenv('bot_token')

recipients_raw = os.getenv("for_whom_list", "")
recipients = [r.strip() for r in recipients_raw.split(",") if r.strip()]
if not recipients:
    raise ValueError("‚ùå –ù–µ—Ç –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π. –£–±–µ–¥–∏—Å—å, —á—Ç–æ for_whom_list –∑–∞–¥–∞–Ω –≤ .env")




from pyrogram import Client, idle

#################  –≤–µ—Ä–Ω—É—Ç—å 
client = Client(name='me_client', api_id=api_id, api_hash=api_hash, bot_token = bot_token )
# –ó–∞–ø—É—Å–∫ –∫–ª–∏–µ–Ω—Ç–∞
client.start()

        


check_if_need_new_rec()
# send_info_ruonia(client, recipients)
send_ai(client, recipients)


# idle()

# –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
client.stop()

#################### –≤–µ—Ä–Ω—É—Ç—å 







